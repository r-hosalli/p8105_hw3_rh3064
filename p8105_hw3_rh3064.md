p8105_hw3_rh3064
================
Rahul Hosalli
2022-10-17

# Problem 2

## Data Loading

``` r
accel_data <- read_csv("./Data/accel_data.csv")
```

    ## Rows: 35 Columns: 1443
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr    (1): day
    ## dbl (1442): week, day_id, activity.1, activity.2, activity.3, activity.4, ac...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

## Data Tidying/Wrangling

The following chunk of code cleans the column names with
`janitor::clean_names()`, then using `mutate()` creates a new variable
*day_type* which indicates if it was a weekend or weekday. *day* and
*day_type* are coerced into factors.

Finally `relocate()` is used to reorder the tibble so that more useful
columns are first (*day_id*, *week*, *day*, *day_type*).

`head()` is used to take a glance at the tibble and check the variable
classes, which seem reasonable.

Finally a new dataset is created by pivoting the original data with
`pivot_longer()` so that the data is tidy.

``` r
accel_data <- 
  accel_data %>%
  janitor::clean_names() %>%
  mutate(
    
    day_type = case_when(day == "Saturday" | day == "Sunday" ~ "Weekend",
                         TRUE ~ "Weekday"),
    
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday",
                                 "Friday", "Saturday", "Sunday")),
    day_type = factor(day_type)
    
    ) %>%
  relocate(day_id, week, day, day_type)

head(accel_data)
```

    ## # A tibble: 6 × 1,444
    ##   day_id  week day      day_type activ…¹ activ…² activ…³ activ…⁴ activ…⁵ activ…⁶
    ##    <dbl> <dbl> <fct>    <fct>      <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>
    ## 1      1     1 Friday   Weekday     88.4    82.2    64.4    70.0    75.0    66.3
    ## 2      2     1 Monday   Weekday      1       1       1       1       1       1  
    ## 3      3     1 Saturday Weekend      1       1       1       1       1       1  
    ## 4      4     1 Sunday   Weekend      1       1       1       1       1       1  
    ## 5      5     1 Thursday Weekday     47.4    48.8    46.9    35.8    49.0    44.8
    ## 6      6     1 Tuesday  Weekday     64.8    59.5    73.7    45.7    42.4    58.4
    ## # … with 1,434 more variables: activity_7 <dbl>, activity_8 <dbl>,
    ## #   activity_9 <dbl>, activity_10 <dbl>, activity_11 <dbl>, activity_12 <dbl>,
    ## #   activity_13 <dbl>, activity_14 <dbl>, activity_15 <dbl>, activity_16 <dbl>,
    ## #   activity_17 <dbl>, activity_18 <dbl>, activity_19 <dbl>, activity_20 <dbl>,
    ## #   activity_21 <dbl>, activity_22 <dbl>, activity_23 <dbl>, activity_24 <dbl>,
    ## #   activity_25 <dbl>, activity_26 <dbl>, activity_27 <dbl>, activity_28 <dbl>,
    ## #   activity_29 <dbl>, activity_30 <dbl>, activity_31 <dbl>, …

``` r
accel_long <- accel_data %>% 
  pivot_longer(activity_1:activity_1440, 
               names_to = "minute", 
               names_prefix = "activity_", 
               values_to = "activity_count") %>%
  mutate(minute = as.numeric(minute))
```

## Data Description

There are 50400 rows and 6 columns in the *`accel_long`* tibble. There

## Total Activity per Day

Total activity count per day per week is calculated by first grouping
the data using `group_by()` . Next, `summarise()` is used with `sum()`
to calculate the activity totals. This is then piped to `pivot_wider()`
to produce a more readable, non-tidy dataframe which is finally
outputted via `knitr::kable()`.

``` r
accel_long %>%
  group_by(week, day) %>%
  summarise(activity_total = sum(activity_count)) %>%
  pivot_wider(names_from = "day",
              values_from = "activity_total") %>%
knitr::kable(caption = "Total Activity Counts by Week and Day")
```

    ## `summarise()` has grouped output by 'week'. You can override using the
    ## `.groups` argument.

| week |    Monday |  Tuesday | Wednesday | Thursday |   Friday | Saturday | Sunday |
|-----:|----------:|---------:|----------:|---------:|---------:|---------:|-------:|
|    1 |  78828.07 | 307094.2 |    340115 | 355923.6 | 480542.6 |   376254 | 631105 |
|    2 | 295431.00 | 423245.0 |    440962 | 474048.0 | 568839.0 |   607175 | 422018 |
|    3 | 685910.00 | 381507.0 |    468869 | 371230.0 | 467420.0 |   382928 | 467052 |
|    4 | 409450.00 | 319568.0 |    434460 | 340291.0 | 154049.0 |     1440 | 260617 |
|    5 | 389080.00 | 367824.0 |    445366 | 549658.0 | 620860.0 |     1440 | 138421 |

Total Activity Counts by Week and Day

There is no obvious trend in activity count data, although there is a
very count on Saturday in week 4 and 5; this count corresponds to an
activity count of 1 per minute, while the average activity count per
minute is 267.04. This might indicate an error with the accelerometer on
those days, or non-use of the device.

## Plots

``` r
ggplot(accel_long, mapping = aes(minute, activity_count)) +
  geom_line(aes(color = day), alpha =0.7) +
  labs(x = "Minute of the Day", y = "Activity Count") +
  scale_color_viridis(
    name = "Day",
    discrete = TRUE
  )
```

![](p8105_hw3_rh3064_files/figure-gfm/unnamed-chunk-5-1.png)<!-- -->

The largest spike in counts is around the 1250 minute mark, which
corresponds to around around 8:30 to 9:00 PM. The lowest activity is
seen in the first 300 or so minutes, which corresponds to before 5AM,
i.e. when they were asleep. General trends by day are difficult to parse
due to the dense overlap of line plots.

``` r
ggplot(accel_long, mapping = aes(minute, activity_count)) +
  geom_smooth(aes(color = day)) +
  labs(x = "Minute of the Day", y = "Activity Count") +
  scale_color_viridis(
    name = "Day",
    discrete = TRUE
  )
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

![](p8105_hw3_rh3064_files/figure-gfm/unnamed-chunk-6-1.png)<!-- -->

If we use `geom_smooth()` we can get a better sense of activity count
trends by day of the week. There is a spike of activity on Sunday at
around minute 600, which corresponds to 10AM.

# Problem 3

## Data Loading

``` r
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (412759e3) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
data("ny_noaa")
```

## Data Cleaning

Initial the data is cleaned by coercing tmax and tmin into integers.
tmax tmin and prcp are then divided by 10 to get the correct C and mm
values (originally the data is provided in tenths of degrees C or tenths
of mm).

Then, `janitor::clean_names()` is used, and the date is separate into
three columns with `separate()`.

``` r
noaa_df <- ny_noaa %>% 
  mutate(
    tmax = as.integer(tmax)/10,
    tmin = as.integer(tmin)/10,
    prcp = prcp/10
  ) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "dat"), sep = "-")
```
