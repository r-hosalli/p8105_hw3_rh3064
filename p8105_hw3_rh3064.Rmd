---
title: "p8105_hw3_rh3064"
author: "Rahul Hosalli"
date: '`r Sys.Date()`'
output: github_document
---

```{r include=FALSE}
library(tidyverse)
library(viridis)
library(knitr)
```

# Problem 2

## Data Loading

```{r}
accel_data <- read_csv("./Data/accel_data.csv")
```

## Data Tidying/Wrangling

The following chunk of code cleans the column names with `janitor::clean_names()`, then using `mutate()` creates a new variable *day_type* which indicates if it was a weekend or weekday. *day* and *day_type* are coerced into factors.

Finally `relocate()` is used to reorder the tibble so that more useful columns are first (*day_id*, *week*, *day*, *day_type*).

`head()` is used to take a glance at the tibble and check the variable classes, which seem reasonable.

Finally a new dataset is created by pivoting the original data with `pivot_longer()` so that the data is tidy.

```{r}
accel_data <- 
  accel_data %>%
  janitor::clean_names() %>%
  mutate(
    
    day_type = case_when(day == "Saturday" | day == "Sunday" ~ "Weekend",
                         TRUE ~ "Weekday"),
    
    day = factor(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday",
                                 "Friday", "Saturday", "Sunday")),
    day_type = factor(day_type)
    
    ) %>%
  relocate(day_id, week, day, day_type)

head(accel_data)

accel_long <- accel_data %>% 
  pivot_longer(activity_1:activity_1440, 
               names_to = "minute", 
               names_prefix = "activity_", 
               values_to = "activity_count") %>%
  mutate(minute = as.numeric(minute))

```

## Data Description

There are `r nrow(accel_long)` rows and `r ncol(accel_long)` columns in the *`accel_long`* tibble. There

## Total Activity per Day

Total activity count per day per week is calculated by first grouping the data using `group_by()` . Next, `summarise()` is used with `sum()` to calculate the activity totals. This is then piped to `pivot_wider()` to produce a more readable, non-tidy dataframe which is finally outputted via `knitr::kable()`.

```{r}
accel_long %>%
  group_by(week, day) %>%
  summarise(activity_total = sum(activity_count)) %>%
  pivot_wider(names_from = "day",
              values_from = "activity_total") %>%
knitr::kable(caption = "Total Activity Counts by Week and Day")
```

There is no obvious trend in activity count data, although there is a very count on Saturday in week 4 and 5; this count corresponds to an activity count of 1 per minute, while the average activity count per minute is `r round(mean(accel_long$activity_count), 2)`. This might indicate an error with the accelerometer on those days, or non-use of the device.

## Plots

```{r}
ggplot(accel_long, mapping = aes(minute, activity_count)) +
  geom_line(aes(color = day), alpha =0.7) +
  labs(x = "Minute of the Day", y = "Activity Count") +
  scale_color_viridis(
    name = "Day",
    discrete = TRUE
  )
```

The largest spike in counts is around the 1250 minute mark, which corresponds to around around 8:30 to 9:00 PM. The lowest activity is seen in the first 300 or so minutes, which corresponds to before 5AM, i.e. when they were asleep. General trends by day are difficult to parse due to the dense overlap of line plots.

```{r}
ggplot(accel_long, mapping = aes(minute, activity_count)) +
  geom_smooth(aes(color = day)) +
  labs(x = "Minute of the Day", y = "Activity Count") +
  scale_color_viridis(
    name = "Day",
    discrete = TRUE
  )
```

If we use `geom_smooth()` we can get a better sense of activity count trends by day of the week. There is a spike of activity on Sunday at around minute 600, which corresponds to 10AM.

# Problem 3

## Data Loading

```{r}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("ny_noaa")
```

## Data Cleaning

Initial the data is cleaned by coercing tmax and tmin into integers. tmax tmin and prcp are then divided by 10 to get the correct C and mm values (originally the data is provided in tenths of degrees C or tenths of mm).

Then, `janitor::clean_names()` is used, and the date is separate into three columns with `separate()`.

```{r}
noaa_df <- ny_noaa %>% 
  mutate(
    tmax = as.integer(tmax)/10,
    tmin = as.integer(tmin)/10,
    prcp = prcp/10
  ) %>%
  janitor::clean_names() %>%
  separate(date, into = c("year", "month", "dat"), sep = "-")

```
